\documentclass[a4paper,10pt]{article}
\usepackage{graphicx}
\usepackage[left=1.80cm, right=1.80cm, top=2.00cm, bottom=2.00cm]{geometry}
\usepackage{amsmath}
\usepackage[colorlinks]{hyperref}
\usepackage[backend=biber,style=draft]{biblatex}
\usepackage{eurosym}
\usepackage[dvipsnames]{xcolor}
\usepackage{amssymb}
\usepackage{subcaption}
\usepackage{enumitem} % for alphabetical enumeration 
\usepackage{accents}
\usepackage[capitalise]{cleveref}


%opening
\title{}
\author{Fabian Hofmann}

\begin{document}

\maketitle

\begin{abstract}

\end{abstract}

% style operators
\newcommand{\ie}{\textit{i.e.} }
\newcommand{\eg}{\textit{e.g.} }
\newcommand{\ubar}[1]{\underaccent{\bar}{#1}}
\newcommand{\note}[1]{\textcolor{Orange}{#1}}
\newcommand{\vpad}{\vspace{1mm}}
\newcommand{\hpad}{\hspace{15pt}}
\newcommand{\resultsin}[1]{\hspace{6pt} \bot  \hspace{6pt} #1}
\newcommand{\Forall}[1]{\hspace{10pt} \forall \,\, #1 }
\newcommand{\pdv}[2]{\dfrac{\partial #1}{\partial #2}}
\newcommand{\st}{\text{s.t.}\hpad}
%math 



% We consider a power system with minimized total cost $\totalcost$ being subject to supplying demand $\demand$ at node $n$ at time $t$. 
% The change in total cost against variation of the nodal demand
% \begin{align}
% \lmp  =  \pdv{\totalcost}{\demand}
% \end{align}
% defines the Locational Marginal Price $\lmp$ that consumers at node $n$ and time $t$. 
% The total cost $\totalcost$ splits into two cost terms
% \begin{align}
% \totalcost &= \totalDemand +  \totalRest
% \label{eq:total_cost_terms}
% \end{align}
% where $\totalDemand$ combines cost all terms which are sensitive to changes in the nodal demand 
% % \begin{align}
% %  \pdv{\totalDemand}{\demand} \ne 0
% % \end{align}
% and thus determine the LMP,
% \begin{align}
% \lmp = \pdv{\totalDemand}{\demand} 
% \end{align}
% and $\totalRest$ combines cost terms which are independent of $\lmp$, thus 
% \begin{align}
%  0 = \pdv{\totalRest}{\demand} \Forall{i}
% \end{align}
% Due to strong duality the total cost $\totalcost$ minus the exogeous cost term $\totalRest$ is totally payed back by the consumers
% \begin{align}
%  \totalcost - \totalRest = \sum_{n,t} \lmp \demand
% \end{align}
% 




\section{Optimization}


Start with a generic linear objective function over $N$ variables $x_i$
\begin{equation}
 \min_{x_i} f(x) =  \min_{x_i}  \sum_{i=1}^N c_i x_i
\end{equation}
such that they respect linear inequality constraints
\begin{equation}
  \sum_i A_{ji} x_i \leq b_j \hspace{1cm} \mu_j \hspace{1cm} j=1,\dots M
\end{equation}
%     [Linear equality constraints $\sum_i b_i x_i = c$ with $\lambda$ can be replaced by two inequalities $\leq c$, $\geq c$ with $\lambda = \bar{\mu} - \ubar{\mu}$.]\\
The assymetric problem (a problem where $x_i \in \mathbb{R}$) translates to the dual problem of type 
\begin{align}
&\max_{\mu_j} \hpad \sum_{j} b_j \mu_j \\ 
&\st  \sum_{j} A_{ij} \mu_j = c_i
\end{align}

\subsection{Reduction to Binding Constraints}
    
A subset $B$ of the inequality constraints will be binding at the
optimum point $x^*$, i.e. for $j\in B$, $\sum_i A_{ji} x^*_i = b_j$. We
write $A'_{ji}$ for the matrix that only runs over $j\in B$. For
non-degenerate solutions these will be enough binding constraints to
solve for a unique optimum $x^*$, i.e. $|B| = N \leq M$, so that $A'$ is an $N\times N$
square matrix.  Therefore we can invert the saturation equation to get
\begin{equation}
  x^*_i = \sum_{j\in B} A^{\prime -1}_{ij} b_j
\end{equation}
It might seem that we've now lost all information about the objective function in this expression for $x^*$, but remember that it is the objective function which determines which constraints are binding, i.e. which vertex of the feasible simplex is the optimum.\\
% 
The matrix $A^{\prime}$ allows switching back and forth between primal and dual space
\begin{align}
b_j = \sum_i x^*_i \, A'_{i,j} \hspace{10pt} \leftrightarrow \hspace{10pt} x^*_i = \sum_j {A'}_{i,j}^{-1} \, b_j \\
c_i = \sum_j A'_{i,j} \, \mu^*_j  \hspace{10pt} \leftrightarrow \hspace{10pt} \mu^*_j = \sum_i c_i \, {A'}_{i,j}^{-1}
\end{align}
The solutions of both problems are connected through
\begin{align}
\sum_i c_i \, x^*_i = \sum_{i,j}  c_i \, {A'}^{-1}_{ij} b_j = \sum_{i,j} x^*_i \, A'_{i,j} \, \mu^*_j = \sum_j \mu^*_j \, b_j 
\end{align}




\subsection{Shifting Coefficients}
Consider a subset $R$ with $| R | \le M- N$ of constraints which we want to exclude from the problem. Therefore we shift the cost coefficients such that they reflect the costs of the removed constraints,
\begin{align}
 \tilde{c}_i &= c_i - \sum_{j \in R} A_{ij} \mu^*_j \\
 &= \sum_{j \notin R} A_{ij} \mu^*_j   \label{eq:coeff_shift}
\end{align}
Solving the shifted objective function $\tilde{f}(x)$ with reduced number of constraints,
\begin{align}
&\min_{x_i} \hpad \sum_{i=1}^N \tilde{c}_i  x_i \\
&\st  \sum_i A_{ij} x_i \le b_j \Forall{j \notin R}
\end{align}
yields the solution $\tilde{x}^*_i$. Will $\tilde{x}^*_i$ still satisfy the removed constraints 
\begin{align}
 \sum_i A_{ij} \tilde{x}^*_i \le b_j \Forall{j \in R} 
\end{align}
even though they are not explicit constraints to the problem anymore? We write down the reduced dual problem,
\begin{align}
& \max_{\mu_j} \hpad \sum_{j \notin R} b_j \mu_j  \\
& \st \sum_{j \notin R} A_{ij} \mu_j = \tilde{c}_i \label{eq:shifted_constraints}
\end{align}
which has the solution $\tilde{\mu}^*_j $. Inserting \cref{eq:coeff_shift} into \cref{eq:shifted_constraints} leads us to 
\begin{align}
 \sum_{j \notin R} A_{ij} \tilde{\mu}^*_j = \sum_{j \notin R} A_{ij} \mu^*_j 
\end{align}
which shows that the common dual variables of the reduced problem and the original problem are the same,
\begin{align}
 \tilde{\mu}^*_j =  \mu^*_j \Forall{j \notin R}
\end{align}
and thus $B - R \subseteq \tilde{B}$. 


Consequently the binding constraints matrix 
\begin{align}
 \tilde{A}^{\prime}_{ij} =  A^{\prime}_{ij} \Forall{i, j \in B - R}
\end{align}









% The shifted objective function is then
% \begin{align}
%  \min_{x_i} f^{\prime}(x) =  \min_{x_i}  \sum_{i=1}^N \left( c_i + c^{ex}_i \right)  x_i
% \end{align}
% where 
% \begin{align}
%  c_i^{ex} = \sum_{j \notin D} A^{\prime}_{ij} \mu_j 
% \end{align}
% yields a solution where all variable are bound by the subset D of constraints, 
% \begin{align}
%   \sum_i A^{\prime \prime}_{ji} x_i = b_j \hspace{1cm} \m_j \hspace{1cm} j \in D
% \end{align}
% with 
% \begin{align}
%  A^{\prime \prime}_{ji} = A^{\prime}_{ji} \Forall{i \in \{i\, |\, c^{ex}_{i} = 0\}}
% \end{align}







\end{document}
